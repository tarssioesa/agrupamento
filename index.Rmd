---
title: "SINISA 2025"
subtitle: "Técnicas de agrupamento"
author: "Tarssio"
date: "2025-09-03"
output:
  distill::distill_article:
    self_contained: false   # não embute dependências
    toc: true               # ativa sumário lateral
    toc_depth: 3            # profundidade do sumário (capítulos e subcapítulos)
    code_folding: true      # botão para recolher/expandir código
---

```{r}
# Oculta avisos e mensagens de todos os chunks por padrão
knitr::opts_chunk$set(
  echo = TRUE,       # mostra o código (recolhido pelo botão)
  warning = FALSE,   # esconde warnings
  message = FALSE,   # esconde mensagens
  comment = "#>",    # saída “limpa” no bloco
  fig.align = "center"
)
```

## 1. O que é o SINISA?

O **Sistema Nacional de Informações em Saneamento Básico (SINISA)** entrou em operação em 2024, sucedendo o SNIS, em conformidade com a **Lei nº 11.445/2007** (diretrizes nacionais para o saneamento básico) e com o **Novo Marco Legal** estabelecido pela **Lei nº 14.026/2020**.\
**Fontes:** [Ministério das Cidades -- página do SINISA](https://www.gov.br/cidades/pt-br/acesso-a-informacao/acoes-e-programas/saneamento/sinisa), [Lei 11.445/2007 (Planalto)](https://www.planalto.gov.br/ccivil_03/_ato2007-2010/2007/lei/l11445.htm), [Lei 14.026/2020 (Planalalto)](https://www.planalto.gov.br/ccivil_03/_ato2019-2022/2020/lei/l14026.htm)

### Para que serve o SINISA?

O **SINISA** tem por finalidade **coletar, organizar e disponibilizar dados oficiais sobre os serviços de saneamento no Brasil** --- abastecimento de água, esgotamento sanitário, manejo de resíduos sólidos e drenagem urbana --- para **subsidiar políticas públicas, regulação e controle social**, nos termos da legislação vigente.\
**Fontes:** [Ministério das Cidades -- SINISA](https://www.gov.br/cidades/pt-br/acesso-a-informacao/acoes-e-programas/saneamento/sinisa), [Marco Legal do Saneamento](https://www.gov.br/cidades/pt-br/assuntos/saneamento/marco-legal-do-saneamento)

### Suas principais funções são:

1.  **Subsidiar políticas públicas**: apoiar planejamento, regulação e monitoramento dos serviços.\
2.  **Garantir transparência e controle social**: disponibilizar informações sobre cobertura e qualidade dos serviços.\
3.  **Atender às exigências legais**: dar cumprimento às diretrizes da Lei nº 11.445/2007 e às atualizações da Lei nº 14.026/2020.

### Dados principais do SINISA

O **SINISA** organiza informações em módulos temáticos. Exemplos de dados coletados:

1.  **Abastecimento de água**
    -   População atendida e não atendida;\
    -   Volume produzido, distribuído e consumido;\
    -   Índices de perdas na distribuição;\
    -   Qualidade da água;\
    -   Investimentos.
2.  **Esgotamento sanitário**
    -   População atendida com coleta;\
    -   Volumes gerados, coletados e tratados;\
    -   Relação tratamento/coleta;\
    -   Investimentos.
3.  **Resíduos sólidos**
    -   Quantidade coletada;\
    -   Modalidades de coleta (convencional, seletiva, especial);\
    -   Destinação final (aterro sanitário, reciclagem, compostagem etc.);\
    -   Custos operacionais e de capital.
4.  **Drenagem urbana**
    -   Extensão e infraestrutura de drenagem;\
    -   Investimentos e ações de mitigação de enchentes;\
    -   Planos de drenagem e gestão de riscos.
5.  **Gestão e regulação** *(módulo em expansão, com consolidações adicionais previstas)*
    -   Estruturas institucionais e regulatórias;\
    -   Indicadores de governança e capacidade institucional.

### Comentários finais:

Trabalharemos com um recorte de **água e esgoto** para ilustrar aplicações analíticas (agrupamento e comparação). Variáveis utilizadas:

1.  **Natureza Jurídica**\
2.  **DFE0001** → População residente total\
3.  **IAG0001** → Atendimento da população total com rede de abastecimento de água\
4.  **IAG2007** → Consumo residencial médio per capita de água\
5.  **IAG2013** → Perdas totais de água na distribuição\
6.  **IES0001** → Atendimento da população total com rede coletora de esgoto\
7.  **IES0007** → Atendimento dos domicílios totais com coleta **e** tratamento de esgoto

## Bibliotecas utilizadas:

```{r}
require(tidyverse)
require(readxl)
library(geobr) 
library(sf)
library(plotly)
library("FactoMineR")
library(factoextra)
library(cluster)   # silhouette()
library(scales)
library(clusterCrit)
library(glue)
```

## Carregando os arquivos:

### Estados e Brasil:

Para um panorama inicial, utilizaremos um subconjunto de variáveis.

```{r}

df_brasil <- read_xlsx("data/agua_sanea_ias_uf.xlsx", sheet = 2) |> 
  filter(UF == "BR") |> 
  select(UF, IAG0001, IES0001, IES0007)

df_regiao <- read_xlsx("data/agua_sanea_ias_uf.xlsx", sheet = 2) |> 
  filter(UF != "BR") |> 
  filter(Estado != "Sergipe") |>  #Sigla de sergipe é igual a sigla de Sudoeste
  select(UF, IAG0001, IES0001, IES0007)

df_uf <- read_xlsx("data/agua_sanea_ias_uf.xlsx") |> 
  select(UF, IAG0001, IES0001, IES0007) |> 
  # Adicionando Sergipe
  bind_rows(
     read_xlsx("data/agua_sanea_ias_uf.xlsx", sheet = 2) |> 
     filter(UF != "BR") |> 
     filter(Estado == "Sergipe") |>  #Sigla de sergipe é igual a sigla de Sudoeste
     select(UF, IAG0001, IES0001, IES0007)
  )

```

### Municípios

Aqui precisamos de uma estratégia para abrir os dados originais e capturar as variáveis que precisamos:

```{r}


# Lista dos arquivos na pasta data
files <- list.files("data", pattern = "\\.xlsx$", full.names = TRUE)[2:4]

# Função para processar cada arquivo
process_one_file <- function(arquivo) {
  # Definir o valor de skip com base no nome do arquivo
  skip_value <- case_when(
    grepl("Indicadores", arquivo) ~ 9,  # Para arquivos 1 e 2
    grepl("Administrativo", arquivo) ~ 10,  # Para o terceiro arquivo
    TRUE ~ 9  # Valor default
  )
  
  sheets <- setdiff(excel_sheets(arquivo), "Nota metodológica")
  
  df_final <- tibble(cod_IBGE = 1232131231) # código fictício para o join
  
  # Ler todas as abas
  for (sh in sheets) {
    df <- read_excel(arquivo, sheet = sh, skip = skip_value)
    df_final <- left_join(df, df_final)
  }
  
  df_final
}

# Aplicar a função a todos os arquivos e juntar os resultados
lista_df <- map(files, process_one_file)

# Juntar todos os arquivos
df_municipios <- reduce(lista_df, ~ left_join(.x, .y)) |> 
  select(cod_IBGE, Macrorregião, UF, `Município`,  CAD0002, DFE0001, 
         IAG0001, IAG2013, IAG2007, IES0001, IES0007)


```

## Explorando os dados:

O Brasil tinha, em 2023, a cobertura de acesso ao abastecimento de água total de 83,1%, enquanto a cobertura da coleta de esgoto era da ordem de 60%. Apenas 45% do esgoto produzido é coletado e tratado --- isto é, cerca de 15% do esgoto coletado não é tratado --- indicando um desafio que vai além da expansão da rede de coleta.

Esses resultados são bastante heterogêneos entre as grandes regiões do país. Enquanto as regiões Centro-Oeste, Sudeste e Sul têm coberturas de abastecimento próximas ou acima de 90%, as regiões Norte e Nordeste apresentam valores bem mais baixos. O desafio da universalização torna-se ainda maior quando se consideram as metas de coleta e tratamento de esgoto (90% da população até 2033).

```{r}
# Primeiro baixaremos os dados do geobr:

br_reg <- read_region(year = 2020) |> 
  st_as_sf() |>
  mutate(
    reg_abbr = dplyr::recode(name_region,
      "Norte" = "N", "Nordeste" = "NE",
      "Sudeste" = "SE", "Sul" = "S",
      "Centro Oeste" = "CO", "Centro-Oeste" = "CO",
      .default = NA_character_
    )
  )

# Ajustando labels para as variáveis sairem com nomes melhores nos gráficos: 

variable_labels <- c(
  IAG0001 = "Atendimento de Água (%)",
  IES0001 = "Coleta de Esgoto (%)",
  IES0007 = "Tratamento sobre Coleta (%)"
)

# Ajustando os dados para podermos criarmos 3 gráficos em uma tela apenas:

df_long <- df_regiao |>
  pivot_longer(
    cols = c(IAG0001, IES0001, IES0007),
    names_to = "indicador", values_to = "valor"
  ) |>
  mutate(indicador_label = recode(indicador, !!!variable_labels))

map_dat <- br_reg |>
  left_join(df_long, by = c("reg_abbr" = "UF"))

# O Gráfico em sí: 
ggplot(map_dat) +
  geom_sf(aes(fill = valor), color = "white", size = 0.3) +
  geom_sf_text(aes(label = round(valor, 1)), size = 3, color = "black") +
  facet_wrap(~ indicador_label, ncol = 3) +
  scale_fill_continuous(name = "Valor (%)") +
  labs(
    title = "Indicadores de Saneamento por Macrorregião",
    subtitle = "Fonte: SINISA (ano-base conforme seu quadro)",
    caption = "Elaboração própria com geobr/IBGE"
  ) +
  theme_void(base_size = 12) +
  theme(
    strip.text = element_text(face = "bold"),
    legend.position = "right",
    plot.title = element_text(face = "bold")
  )

```

Outra forma de ver estes dados é por Estado, mostrando desigualdades intrarrregionais. Abaixo temos, respectivamente, a cobertura de abastecimento de água e a de coleta e tratamento de esgoto.

### Abastecimento de água:

```{r}

# Carregando os Estados: 

br_states <-
  suppressMessages(read_state(year = 2020,  
                              simplified = TRUE) |>
                     st_as_sf())

# Ajustando os dados:

df_long <- df_uf |>
  pivot_longer(
    cols = c(IAG0001),
    names_to = "indicador", values_to = "valor"
  ) |>
  mutate(indicador_label = recode(indicador, !!!variable_labels))

map_dat <- br_states |>
  left_join(df_long, by = c("abbrev_state" = "UF"))

# Os gráficos: 

p <- ggplot(map_dat) +
  geom_sf(aes(fill = valor), color = "white", size = 0.2) +
  facet_wrap(~ indicador_label, ncol = 3) +
  scale_fill_continuous(name = "Valor (%)") +
  labs(
    title = "Indicadores de Saneamento por Estado",
    subtitle = "Fonte: SINISA (2025)",
    caption = "Elaboração própria com geobr/IBGE"
  ) +
  theme_void(base_size = 11) +
  theme(
    strip.text = element_text(face = "bold"),
    legend.position = "right",
    plot.title = element_text(face = "bold")
  )

# da para melhorar bastante o gráfico
ggplotly(p, tooltip = "fill")

```

### Coleta e tratamento de esgoto:

A situação da coleta e tratamento de esgoto é crítica. Enquanto São Paulo e Paraná avançam na cobertura e no tratamento (na ordem de \~70%), boa parte dos Estados permanece em torno de 50%, e há um grupo relevante abaixo de 30%.

```{r}

# Carregando os Estados: 

br_states <- read_state(year = 2020,  simplified = TRUE) |> st_as_sf()

# Ajustando os dados:

df_long <- df_uf |>
  pivot_longer(
    cols = c(IES0007),
    names_to = "indicador", values_to = "valor"
  ) |>
  mutate(indicador_label = recode(indicador, !!!variable_labels))

map_dat <- br_states |>
  left_join(df_long, by = c("abbrev_state" = "UF"))

# Os gráficos: 

p <- ggplot(map_dat) +
  geom_sf(aes(fill = valor), color = "white", size = 0.2) +
  facet_wrap(~ indicador_label, ncol = 3) +
  scale_fill_continuous(name = "Valor (%)") +
  labs(
    title = "Indicadores de Saneamento por Estado",
    subtitle = "Fonte: SINISA (2025)",
    caption = "Elaboração própria com geobr/IBGE"
  ) +
  theme_void(base_size = 11) +
  theme(
    strip.text = element_text(face = "bold"),
    legend.position = "right",
    plot.title = element_text(face = "bold")
  )

# da para melhorar bastante o gráfico
ggplotly(p, tooltip = "fill")

```

Dado este panorama mais geral, partimos para agrupar os municípios, buscando encontrar uma lógica de similaridade que ajude a compreender este fenômeno.

### Limpeza e ajuste do banco de dados

Tomaremos duas decisões afim de facilitar o andamento desta análise pré-liminar que tem como objetivo principal debater métodos de agrupamento:

1.  Nas variáveis de esgoto, a falta de informação significa que não há coleta, logo a cobertura será igual a 0;
2.  Serão excluídos os municípios que possuem alguma variável não informada no que tange a características do abastecimento de água;

```{r}

df_final <- df_municipios |> 
  mutate(across(6:11, as.numeric)) |> 
  mutate(across(10:11, ~ifelse(is.na(.), 0, .)))  |>
  dplyr::select(-IAG2007) |> 
  filter(`Município` != "São Paulo") |> 
  na.omit()

```

Ficamos assim com cerca de 4000 municípios.

## Um pouco sobre o que é agrupamento:

### 1) O que é **agrupamento** em ciência de dados

Clustering é a **classificação não supervisionada** de observações em grupos de alta similaridade interna e baixa similaridade externa, sem rótulos pré-existentes.

------------------------------------------------------------------------

### 2) Principais categorias de métodos

-   **Centróide/particionamento**: p.ex., *k*-means/*k*-medoids.\
-   **Distribucionais/probabilísticos**: Misturas de Gaussianas (EM).\
-   **Densidade**: DBSCAN, HDBSCAN.\
-   **Hierárquicos (conectividade/aglomerativos)**: *single*, *complete*, *average* linkage.

------------------------------------------------------------------------

### 3) **Silhouette**: o que é e como escolher *k*

Para cada ponto *i*, define-se **a(i)** (distância média ao seu cluster) e **b(i)** (menor distância média ao cluster vizinho); o coeficiente é\
**s(i) = (b(i) − a(i)) / max{a(i), b(i)}**, variando de −1 (má alocação) a +1 (clusters bem separados). A **média de s(i)** avalia a qualidade global e pode orientar a seleção do número de clusters, escolhendo o *k* que maximiza a **silhouette média** (ou analisando o gráfico de silhouette por *k*).

### K-Means

O que é *k*-means e como usar **silhouette** - **k-means** particiona os dados em *k* grupos minimizando a soma das distâncias quadráticas aos **centróides** (variância intra-clusters).

```{r}
# 1) Dados e padronização
X <- scale(df_final[, 6:10])

# 2) Função: silhouette média para um k
avg_sil <- function(k) {
  set.seed(123)
  km <- kmeans(X, centers = k, nstart = 25)
  sil <- silhouette(km$cluster, dist(X))
  mean(sil[, "sil_width"])
}

# 3) Avaliar k de 2 a 10
ks <- 2:10
sil_means <- sapply(ks, avg_sil)
best_k <- ks[which.max(sil_means)]

glue("Número ótimo de grupos: {best_k}")

# 4) Gráfico da silhouette média por k
df_sil <- data.frame(k = ks, sil = sil_means)
ggplot(df_sil, aes(k, sil)) +
  geom_line() + geom_point(size = 2) +
  geom_vline(xintercept = best_k, linetype = 2) +
  labs(title = "Silhouette média por k", x = "k", y = "Silhouette média") +
  theme_minimal()

```

Dado que o melhor número de grupos apresentado foram duas. É interessante observar que se dividiu em um grupo que é representado principalmente por cidades com maior população e melhores indicadores no geral. Ainda é uma divisão pouco útil, vamos explorar outros métodos a seguir.

```{r}

km_best <- kmeans(X, centers = best_k, nstart = 25)

# Variáveis que formarão os boxplots:
vars <- c("DFE0001","IAG0001","IAG2013","IES0001","IES0007")

# Labels para o gráfico:
labels <- c(
  DFE0001 = "População residente",
  IAG0001 = "Atendimento de Água (%)",
  IAG2013 = "Perdas na distribuição (%)",
  IES0001 = "Coleta de esgoto (%)",
  IES0007 = "Coleta + Tratamento (%)"
)

# Ajustando o banco de dados: 
df_long <- df_final |>
  mutate(cluster = km_best$cluster) |> 
  mutate(DFE0001 = log10(DFE0001)) |> 
  dplyr::select(cluster, all_of(vars)) |>
  mutate(cluster = factor(cluster)) |>
  pivot_longer(-cluster, names_to = "variavel", values_to = "valor") |>
  mutate(variavel = recode(variavel, !!!labels))

# Gráfico
ggplot(df_long, aes(x = cluster, y = valor, fill = cluster)) +
  geom_boxplot(outlier.alpha = 0.25, width = 0.7) +
  facet_wrap(~ variavel, scales = "free_y") +
  scale_y_continuous(labels = label_number(accuracy = 0.1, decimal.mark = ",")) +
  guides(fill = "none") +
  labs(
    title = "Distribuições por variável e cluster",
    x = "Cluster", y = NULL,
    caption = "Elaboração própria"
  ) +
  theme_minimal(base_size = 12)

```

### Usando o k-medoides:

**k-medoides** é um método de **particionamento** que escolhe, como centros, **observações reais** (medoides) e atribui cada ponto ao medoide mais próximo, **minimizando a soma das dissimilaridades** (pode ser qualquer métrica/ distância, não apenas Euclidiana). Diferente do *k-means*, é **mais robusto a outliers** e funciona com matrizes de distância não-vetoriais.

**Algoritmo (PAM, "Partitioning Around Medoids")**\
1) Seleciona *k* medoides iniciais; 2) **Atribui** pontos ao medoide mais próximo; 3) **Troca** (swap) medoide↔não-medoide quando reduz o custo total; 4) Repete até convergir. Custo clássico é alto em *n*, por isso há variantes **CLARA** (amostragem) e **CLARANS** (busca aleatória), e otimizações recentes como **FastPAM**.

**Quando usar**\
- Dados com **outliers** ou com **métricas gerais** (Manhattan, DTW, edit distance, distâncias em grafos).\
- Quando é útil que o "centro" seja um **exemplo representativo real** (interpretabilidade).

**Limitações**\
- **Mais custoso** que *k-means*; depende de *k*; pode prender em **ótimos locais** (mitigue com múltiplas inicializações).

Vamos testar também outra métrica que favorece número maior de grupo:

### Índice Davies--Bouldin (DB)

O índice **Davies--Bouldin (DB)** é uma métrica de avaliação interna de agrupamentos proposta por Davies e Bouldin (1979). Ele mede a média da razão entre a *dispersão intra-cluster* e a *separação inter-cluster*.

### Intuição

Para cada cluster $i$, o índice calcula sua similaridade com o cluster mais próximo $j$, considerando: - **Dispersão intra-cluster (**$S_i$): raio médio das distâncias entre os pontos do cluster e seu centróide.\
- **Distância inter-cluster (**$M_{ij}$): distância entre os centróides de $i$ e $j$.

A razão $(S_i + S_j)/M_{ij}$ **penaliza sobreposição** entre clusters.

### Fórmula

$$
DB = \frac{1}{k} \sum_{i=1}^k \max_{j \ne i} \frac{S_i + S_j}{M_{ij}}
$$

onde $k$ é o número de clusters.

### Interpretação

-   Quanto **menor** o índice DB, **melhor** a partição --- clusters mais compactos e bem separados.\
-   Valores altos indicam **sobreposição** entre clusters.

### Uso prático

-   Especialmente útil em *comparações de soluções com diferentes números de clusters (k)*.\
-   Frequentemente usado em conjunto com outros índices (Silhouette, Dunn, Calinski--Harabasz).\
-   Sensível a clusters não esféricos.

```{r}
### Funcao para fazer o k-mediode
db_pam <- function(k){
  set.seed(123)
  fit <- pam(X, k = k, metric = "euclidean", pamonce = 3)
  part <- as.integer(fit$clustering)
  ic   <- intCriteria(as.matrix(X), part, "Davies_Bouldin")
  ic$davies_bouldin
}

### Buscando melhor k

db_vals <- sapply(ks, db_pam)
best_k_db <- ks[which.min(db_vals)]

glue("Número ótimo de grupos: {best_k_db}")

# Plot DB por k
tibble(k = ks, db = db_vals) |>
  ggplot(aes(k, db)) +
  geom_line() + geom_point(size = 2) +
  geom_vline(xintercept = best_k_db, linetype = 2) +
  labs(title = "Davies–Bouldin por k (PAM)", x = "k", y = "DB (menor é melhor)") +
  theme_minimal()

```

Número ideal de grupos igual a 10, veremos quais diferenças são obtidas para o agrupamento anterior:

```{r}
# Incluindo cluster
pam_best <- pam(X, k = best_k_db, metric = "euclidean")

# -----------------------------
# Boxplots por variável × cluster (mesmo esquema)
# -----------------------------
labels <- c(
  DFE0001 = "População residente",
  IAG0001 = "Atendimento de Água (%)",
  IAG2013 = "Perdas na distribuição (%)",
  IES0001 = "Coleta de esgoto (%)",
  IES0007 = "Coleta + Tratamento (%)"
)

# Ajustando o banco de dados

df_long <- df_final |>
  mutate(cluster_kmed = factor(pam_best$clustering)) |> 
  mutate(DFE0001 = log10(DFE0001)) |> 
  select(cluster_kmed, all_of(vars)) |>
  pivot_longer(-cluster_kmed, names_to = "variavel", values_to = "valor") |>
  mutate(variavel = recode(variavel, !!!labels))

# Gráfico

ggplot(df_long, aes(x = cluster_kmed, y = valor, fill = cluster_kmed)) +
  geom_boxplot(outlier.alpha = 0.25, width = 0.7) +
  facet_wrap(~ variavel, scales = "free_y") +
  scale_y_continuous(labels = label_number(accuracy = 0.1, decimal.mark = ",")) +
  labs(title = "Distribuições por variável e cluster (PAM/k-medoides)",
       x = "Cluster (k-medoides)", y = NULL, fill = "Cluster") +
  guides(fill = "none") +
  theme_minimal(base_size = 12)
```

Vamos completar este gráfico com uma tabela:

```{r}

tab <- df_long |>
  group_by(cluster_kmed, variavel) |>
  summarise(mediana = median(valor, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = variavel, values_from = mediana) |>
  mutate(`População residente` = round(10^`População residente`, 0))

DT::datatable(
  tab,
  rownames = FALSE,
  fillContainer = TRUE,
  width = "100%",
  class = "compact stripe hover",
  options = list(
    paging = FALSE,
    autoWidth = TRUE,
    scrollX = TRUE,
    scrollY = "500px",   # <<< altura em pixels (aumente conforme necessário)
    info = FALSE,
    searching = FALSE
  )
)

```

Podemos distinguir alguns grupos:

1.  O grupo **8** é aquele de maior população mediana. São grandes cidades e que possuem os melhores indicadores, cobertura mediana de água próximo a 100%, coleta de esgoto de cerca de 85%, mediana, e ainda cerca de 50% do esgoto coletado e tratado.

2.  O grupo **9** e **10** são compostos por cidades com mediana de 20 mil pessoas que possuem altos indicadores para todas variáveis, seriam cidades modelos no saneamento. É interessante que são cidades que a mediana da população não chega a 100 mil pessoas.

3.  Os outros sete grupos são de cidades ainda menores, com populações bem reduzidas, que não possuem coleta de esgoto, mas apresentam grande variabilidade no que tange a cobertura do abastecimento de água.

4.  Dentre estes sete grupos destaca-se o grupo **3** que são cidades que mesmo pequenas possuem, em sua maioria, coleta de esgoto, porém não tratamento ou parte diminuta tratada. Outros grupos que se destacam são o **5 e 7** por terem baixa cobertura de abastecimento de água, por estarem falhando no mais básico.

Estes dois métodos apresentados são os métodos baseado em centroides e particionamento, a seguir trabalharemos com métodos **Distribucionais/probabilísticos**

## Quando usar Kmeans ou K-medoids

1.  K-means quando tem muitos dados numéricos limpos e homogêneos.
2.  K-medoids quando há outliers, variáveis categóricas ou mistura de escalas, ou quando a interpretabilidade dos centros como casos reais importa.
